{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed7ba3-85fc-4129-8284-b53a6bfdd15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pandas import ExcelWriter\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from loguru import logger\n",
    "import sqlite3\n",
    "''' Install these through terminal if not already installed '''\n",
    "# pip install sql\n",
    "# pip install sqlmagic\n",
    "# pip install jupysql\n",
    "# pip install sqlalchemy\n",
    "# pip install ipython-sql\n",
    "\n",
    "pandas.set_option(\"display.max_rows\", None)\n",
    "pandas.set_option(\"display.max_columns\", None)\n",
    "pandas.set_option(\"display.width\", None)\n",
    "pandas.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Import jupysql Jupyter extension to create SQL cells.\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e23092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "''' Point the directory_of_interest to the folder with data files you want to analyze '''\n",
    "\n",
    "directory_of_interest = (\n",
    "    \"/Users/carstenjuliansavage/PycharmProjects/Random_Project/Data Files\"\n",
    ")\n",
    "\n",
    "analysis_file_name = \"analysis_file\"\n",
    "\n",
    "excel_analysis_output_path = f\"{directory_of_interest}/{analysis_file_name}.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0653b-66d0-4090-b9c2-a8f829d4cf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "''' Concatenate all the dataframes together and create master dataset '''\n",
    "def concat_all_data(directory):\n",
    "    os.chdir(directory)\n",
    "\n",
    "    # Import files\n",
    "    path = \"*\"\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    combined_files = pandas.DataFrame()\n",
    "\n",
    "    logger.info(\"Importing Files\")\n",
    "\n",
    "    list_of_dfs = []\n",
    "\n",
    "    for each_file in files:\n",
    "        if \"xlsx\" in each_file:\n",
    "            df = pandas.read_excel(each_file, engine=\"openpyxl\")\n",
    "            df[\"File_Name\"] = each_file\n",
    "            df[\"Row_Number\"] = df.index + 2\n",
    "            list_of_dfs.append(df)\n",
    "        elif \"xls\" in each_file:\n",
    "            df = pandas.read_excel(each_file)\n",
    "            df[\"File_Name\"] = each_file\n",
    "            df[\"Row_Number\"] = df.index + 2\n",
    "            list_of_dfs.append(df)\n",
    "        elif \"csv\" in each_file:\n",
    "            df = pandas.read_csv(each_file)\n",
    "            df[\"File_Name\"] = each_file\n",
    "            df[\"Row_Number\"] = df.index + 2\n",
    "            list_of_dfs.append(df)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    combined_files = pandas.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "    logger.info(\"Finished Importing Files\")\n",
    "\n",
    "    return combined_files\n",
    "\n",
    "''' Create a summary of the data types and counts of master data'''\n",
    "def create_summary_of_data(data_for_summary):\n",
    "    logger.info(\"Building non-null summary of data\")\n",
    "\n",
    "    counts_by_file = pandas.DataFrame(data_for_summary.groupby(\"file_name\").count())\n",
    "    counts_by_file = counts_by_file.transpose()\n",
    "\n",
    "    counts_by_file = counts_by_file.astype(\"int\")\n",
    "\n",
    "    counts = pandas.DataFrame(data_for_summary.count())\n",
    "\n",
    "    master_dtypes = pandas.DataFrame(master_dataframe.dtypes)\n",
    "\n",
    "    counts_master_and_all = pandas.concat(\n",
    "        [master_dtypes, counts, counts_by_file], axis=1\n",
    "    )\n",
    "\n",
    "    counts_master_and_all.columns.values[0] = \"Master_Dataset_Dtype\"\n",
    "\n",
    "    counts_master_and_all.columns.values[1] = \"Master_Dataset_Non_Null\"\n",
    "\n",
    "    counts_master_and_all.drop(\"file_name\", axis=0, inplace=True)\n",
    "\n",
    "    return counts_master_and_all\n",
    "\n",
    "''' Create a summary of which dataframes contain which columns '''\n",
    "def get_column_names(combined_files):\n",
    "    logger.info(\"Creating summary of names of non-null columns\")\n",
    "\n",
    "    # Get first 20 rows from each source doc, shuffle obs. to increase probability of obs. in the sample.\n",
    "    combined_files_random_sample = (\n",
    "        combined_files.sample(frac=1, random_state=47)\n",
    "        .groupby([\"file_name\"])\n",
    "        .head(20)\n",
    "        .set_index([\"file_name\"])\n",
    "    )\n",
    "\n",
    "    # Get column names for files where data exists for those columns\n",
    "    non_na_rows = (\n",
    "        combined_files_random_sample.stack()\n",
    "        .reset_index(level=1)\n",
    "        .groupby(level=0, sort=False)[\"level_1\"]\n",
    "        .apply(list)\n",
    "    )\n",
    "\n",
    "    non_na_rows = pandas.DataFrame(non_na_rows)\n",
    "\n",
    "    non_na_rows[\"level_1\"] = list(map(set, non_na_rows[\"level_1\"]))\n",
    "\n",
    "    return non_na_rows\n",
    "\n",
    "''' Get counts for each variable in master dataset '''\n",
    "def get_frequency_table(dataset):\n",
    "    list_of_dfs = []\n",
    "    for column in dataset:\n",
    "        column_frequency = dataset[column].value_counts()\n",
    "        column_frequency_df = pandas.DataFrame(column_frequency)\n",
    "        list_of_dfs.append(column_frequency_df)\n",
    "    return list_of_dfs\n",
    "\n",
    "''' Get frequency table for each variable in master dataset '''\n",
    "def get_frequency_table_sheets(dataset):\n",
    "    logger.info(\"Creating list of dataframes\")\n",
    "    all_frequency_table_sheets_list = []\n",
    "    for i in range(len(dataset.columns)):\n",
    "        frequency_table_sheet = (\n",
    "            dataset.groupby(dataset.columns[i])\n",
    "            .size()\n",
    "            .to_frame(name=\"Count\")\n",
    "            .join(\n",
    "                dataset.groupby(dataset.columns[i])\n",
    "                .size()\n",
    "                .apply(lambda x: x / len(dataset))\n",
    "                .rename(\"% of Total\")\n",
    "            )\n",
    "            .sort_values(by=\"Count\", ascending=False)\n",
    "        )\n",
    "        all_frequency_table_sheets_list.append(frequency_table_sheet)\n",
    "\n",
    "    return all_frequency_table_sheets_list\n",
    "\n",
    "''' Save frequency tables, one per sheet, to Excel file '''\n",
    "def save_frequency_tables_xls(list_dfs, xls_path, list_of_column_names):\n",
    "    logger.info(\"Creating analysis Excel file\")\n",
    "\n",
    "    master_summary_stats_by_file = (\n",
    "        master_dataframe.groupby([\"file_name\"])\n",
    "        .describe(include=\"all\", datetime_is_numeric=True)\n",
    "        .transpose()\n",
    "    )\n",
    "    master_summary_stats_all = master_dataframe.describe(\n",
    "        include=\"all\", datetime_is_numeric=True\n",
    "    ).transpose()\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        master_summary_stats_all.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"Summary Stats CombinedFile\",\n",
    "            index=True,\n",
    "            header=True,\n",
    "            freeze_panes=(1, 0),\n",
    "        )\n",
    "        master_summary_stats_by_file.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"Summary Stats ByFile\",\n",
    "            index=True,\n",
    "            header=True,\n",
    "            freeze_panes=(1, 0),\n",
    "        )\n",
    "        summary_of_master_data.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"Summary Master Data\",\n",
    "            index=True,\n",
    "            header=True,\n",
    "            freeze_panes=(1, 0),\n",
    "        )\n",
    "        non_na_rows_all.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"Column Names ByFile\",\n",
    "            index=True,\n",
    "            header=True,\n",
    "            freeze_panes=(1, 0),\n",
    "        )\n",
    "        sheet_separator = pandas.DataFrame()\n",
    "        sheet_separator.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"Frequency Tables ByColumn>>\",\n",
    "            index=True,\n",
    "            header=True,\n",
    "            freeze_panes=(1, 0),\n",
    "        )\n",
    "        for df, column_name in zip(list_dfs, list_of_column_names):\n",
    "            df.to_excel(\n",
    "                writer,\n",
    "                sheet_name=column_name,\n",
    "                index=True,\n",
    "                header=True,\n",
    "                freeze_panes=(1, 0),\n",
    "            )\n",
    "\n",
    "    return list_of_column_names\n",
    "\n",
    "''' Convert variable names to Excel-compatible variable names '''\n",
    "def get_valid_excel_column_names(list_of_col_names):\n",
    "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
    "    list_of_col_names = [\n",
    "        \"\".join(c for c in col if c in valid_chars) for col in list_of_col_names\n",
    "    ]\n",
    "    invalid_chars = r\"[\\[\\]:/\\\\?\\*]\"\n",
    "    list_of_col_names = [re.sub(invalid_chars, \"\", col) for col in list_of_col_names]\n",
    "    list_of_col_names = [col[:30].strip() for col in list_of_col_names]\n",
    "    return list_of_col_names\n",
    "\n",
    "''' Rename duplicate columns, adding prefix _1, _2,... '''\n",
    "class ReNamer:\n",
    "    def __init__(self):\n",
    "        self.d = dict()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if x not in self.d:\n",
    "            self.d[x] = 0\n",
    "            return x\n",
    "        else:\n",
    "            self.d[x] += 1\n",
    "            return \"%s_%d\" % (x, self.d[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf44364-5f10-48f4-bf31-719dafd34d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    master_dataframe = concat_all_data(directory_of_interest)\n",
    "    master_dataframe.columns = [x.lower() for x in master_dataframe.columns]\n",
    "    master_dataframe = master_dataframe.rename(columns=ReNamer())\n",
    "    logger.info(master_dataframe.columns)\n",
    "    list_of_columns_in_df = master_dataframe.columns\n",
    "    non_na_rows_all = get_column_names(master_dataframe)\n",
    "    summary_of_master_data = create_summary_of_data(master_dataframe)\n",
    "\n",
    "    list_of_frequency_dfs = get_frequency_table(master_dataframe)\n",
    "\n",
    "    column_names_list = get_valid_excel_column_names(list(master_dataframe.columns))\n",
    "\n",
    "    list_of_all_frequency_table_sheets = get_frequency_table_sheets(\n",
    "        dataset=master_dataframe\n",
    "    )\n",
    "    save_frequency_tables_xls(\n",
    "        list_dfs=list_of_all_frequency_table_sheets,\n",
    "        xls_path=excel_analysis_output_path,\n",
    "        list_of_column_names=column_names_list,\n",
    "    )\n",
    "    logger.info(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f7fa9-2ca2-41b7-be75-192e12c007fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Creating empty database to store master dataset\n",
    "conn = sqlite3.connect('master_dataframe_database.db')\n",
    "\n",
    "logger.info(\"Creating SQL version of master dataframe\")\n",
    "\n",
    "master_dataframe.to_sql('master_dataframe', conn, if_exists='replace',index=False)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd0230-35d8-4d22-b4a8-c9224b14d2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94a915-ee3f-4736-98b8-3e309b432de0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%sql sqlite:///master_dataframe_database.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81840858-fb7e-44f9-86b4-f79b70795224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "logger.info(\"✨ SQL-ready ✨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449f5a4-e78b-4634-912d-8be1d351227d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    master_dataframe\n",
    "WHERE\n",
    "    file_name LIKE '%Analytics%'\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc30ed-e78c-4181-8b4b-f00b827c1b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carstenjuliansavage/PycharmProjects/Random_Project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
